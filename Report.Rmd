---
title: "Predicting workout data"
author: "Simon Lidberg"
date: "October 16th 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(caret)
require(dplyr)
require(readr)
require(e1071)
require(ggplot2)
require(doParallel)
require(gbm)
set.seed(1337)
cl <- makeCluster(10) # Use 10 parallel processes
registerDoParallel(cl)
```

## Loading data
We start by loading the testing data, removing unnecessary columns, and filtering the same columns in our training and validation data. This reduces the number of predictors. We also ignore the first seven columns which are considered unnecessary as well.

```{r LoadData, cache=TRUE, echo=TRUE}
quiztesting <- suppressMessages(suppressWarnings(read.csv("pml-testing.csv", na=c("#DIV/0!", "NA"))[,c(-1:-7, -160)]))
quiztesting <- quiztesting %>% select_if(~sum(!is.na(.)) > 0)

training <- suppressMessages(suppressWarnings(read_csv("pml-training.csv", na=c("#DIV/0!", "NA"))))
training$classe <- as.factor(training$classe)
training <- training %>% select(one_of(colnames(quiztesting)), classe)

trainIdx <- createDataPartition(training$classe, p=0.8, list = FALSE)
data_train <- training[trainIdx,c(-1:-7)] 
data_validation <- training[-trainIdx,c(-1:-7)]
```


## Fitting models
Fitting a random forest model and a stochastic gradient boosting tree model as two classification algorithms. Cross validation is used in the training by the built in trainControl in caret. We're using the cross validation k-fold resampling.

```{r fittingdata, echo=TRUE, cache=TRUE}
ctrl = trainControl(method = "Cv", number = 10)
rfModel <- train(classe~., data = data_train, method = "rf", trControl = ctrl, na.action = na.exclude)

gbmModel <- train(classe~., data = data_train, method = "gbm", trControl = ctrl, na.action = na.exclude)

summary(resamples(list(GBM=gbmModel, RF=rfModel)))
```
After reviewing the accuracies, we pick the random forest model.

## Results
```{r predict, echo=TRUE}
rf.result <- predict(rfModel, newdata = data_validation, na.action = na.exclude)
confusionMatrix(rf.result, na.exclude(data_validation)$classe)

quiz_results <- predict(rfModel, newdata = quiztesting, na.action = na.exclude)
quiz_results
```

The accuracy here is very high, and correctly predicts the quiz.
